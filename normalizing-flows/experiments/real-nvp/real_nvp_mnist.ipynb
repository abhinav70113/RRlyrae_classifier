{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lenny/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow:  2.4.1\n",
      "tensorflow-probability:  0.12.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from normalizingflows.flow_catalog import RealNVP\n",
    "from utils.train_utils import train_density_estimation, nll\n",
    "from data import dataset_loader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 12:08:04.669895: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-16 12:08:04.670391: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "category = 2\n",
    "train_data, val_data, test_data, _ = dataset_loader.load_and_preprocess_mnist(logit_space=True, batch_size=128, shuffle=True, classes=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_shape = (28, 28, 1)\n",
    "size = 28\n",
    "input_shape = size*size\n",
    "permutation = tf.cast(np.concatenate((np.arange(input_shape/2,input_shape),np.arange(0,input_shape/2))), tf.int32)\n",
    "base_dist = tfd.MultivariateNormalDiag(loc=tf.zeros(input_shape, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 1\n",
    "dataset = \"mnist\"\n",
    "exp_number = 1\n",
    "max_epochs = 200\n",
    "layers = 5\n",
    "shape = [256, 256]\n",
    "base_lr = 1e-4\n",
    "end_lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 12:08:05.923315: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "bijectors = []\n",
    "alpha = 1e-3\n",
    "\n",
    "for i in range(layers):\n",
    "    bijectors.append(tfb.BatchNormalization())\n",
    "    bijectors.append(RealNVP(input_shape=input_shape, n_hidden=shape))\n",
    "    bijectors.append(tfp.bijectors.Permute(permutation))\n",
    "    \n",
    "bijectors.append(tfb.Reshape(event_shape_out=(size, size),\n",
    "                                 event_shape_in=(size * size,)))\n",
    "\n",
    "\n",
    "bijector = tfb.Chain(bijectors=list(reversed(bijectors)), name='chain_of_real_nvp')\n",
    "\n",
    "flow = tfd.TransformedDistribution(\n",
    "    distribution=base_dist,\n",
    "    bijector=bijector\n",
    ")\n",
    "\n",
    "# number of trainable variables\n",
    "n_trainable_variables = len(flow.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(base_lr, max_epochs, end_lr, power=0.5)\n",
    "\n",
    "checkpoint_directory = \"{}/tmp_{}_{}_{}_{}_{}\".format(dataset, layers, shape[0], shape[1], exp_number, category)\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate_fn)\n",
    "checkpoint = tf.train.Checkpoint(optimizer=opt, model=flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lenny/uni/AdvMethDataAnalysis/term_paper/tensorflow/normalizing-flows/normalizingflows/flow_catalog.py:220: AffineScalar.__init__ (from tensorflow_probability.python.bijectors.affine_scalar) is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`AffineScalar` bijector is deprecated; please use `tfb.Shift(loc)(tfb.Scale(...))` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lenny/opt/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:2273: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2022-08-16 12:08:09.995730: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, train_loss: 1325.5394287109375, val_loss: 1134.71533203125\n",
      "1, train_loss: 1062.76416015625, val_loss: 965.9075927734375\n",
      "2, train_loss: 914.4681396484375, val_loss: 837.2979736328125\n",
      "3, train_loss: 787.5392456054688, val_loss: 716.618896484375\n",
      "4, train_loss: 675.7529907226562, val_loss: 612.38525390625\n",
      "5, train_loss: 598.2848510742188, val_loss: 580.1678466796875\n",
      "6, train_loss: 572.3732299804688, val_loss: 553.2103271484375\n",
      "7, train_loss: 539.8829956054688, val_loss: 526.51953125\n",
      "8, train_loss: 515.4192504882812, val_loss: 500.64947509765625\n",
      "9, train_loss: 480.37811279296875, val_loss: 475.1078186035156\n",
      "10, train_loss: 443.8014221191406, val_loss: 449.7270202636719\n",
      "11, train_loss: 414.1618957519531, val_loss: 424.8367004394531\n",
      "12, train_loss: 379.9648742675781, val_loss: 400.7292175292969\n",
      "13, train_loss: 351.6256408691406, val_loss: 377.64727783203125\n",
      "14, train_loss: 317.39739990234375, val_loss: 355.55059814453125\n",
      "15, train_loss: 283.036376953125, val_loss: 333.39678955078125\n",
      "16, train_loss: 245.92059326171875, val_loss: 312.75146484375\n",
      "17, train_loss: 200.169189453125, val_loss: 292.6021423339844\n",
      "18, train_loss: 160.76344299316406, val_loss: 273.7236328125\n",
      "19, train_loss: 124.17328643798828, val_loss: 255.4432373046875\n",
      "20, train_loss: 87.2491226196289, val_loss: 240.56369018554688\n",
      "21, train_loss: 54.801883697509766, val_loss: 224.7625274658203\n",
      "22, train_loss: -12.090652465820312, val_loss: 211.4169464111328\n",
      "23, train_loss: -38.72071838378906, val_loss: 202.03463745117188\n",
      "24, train_loss: -78.8996353149414, val_loss: 190.50686645507812\n",
      "25, train_loss: -72.17835235595703, val_loss: 178.57040405273438\n",
      "26, train_loss: -110.40560150146484, val_loss: 174.7908935546875\n",
      "27, train_loss: -141.44216918945312, val_loss: 160.98471069335938\n",
      "28, train_loss: -162.28465270996094, val_loss: 151.17489624023438\n",
      "29, train_loss: -166.95257568359375, val_loss: 146.10064697265625\n",
      "30, train_loss: -190.5037078857422, val_loss: 139.63133239746094\n",
      "31, train_loss: -192.13047790527344, val_loss: 135.83627319335938\n",
      "32, train_loss: -205.46633911132812, val_loss: 131.96954345703125\n",
      "33, train_loss: -212.91481018066406, val_loss: 128.3413848876953\n",
      "34, train_loss: -254.38507080078125, val_loss: 120.04206085205078\n",
      "35, train_loss: -256.1509094238281, val_loss: 114.50798034667969\n",
      "36, train_loss: -263.44134521484375, val_loss: 107.01663208007812\n",
      "37, train_loss: -248.60557556152344, val_loss: 106.13055419921875\n",
      "38, train_loss: -277.6363830566406, val_loss: 102.62379455566406\n",
      "39, train_loss: -302.86553955078125, val_loss: 98.61012268066406\n",
      "40, train_loss: -289.62078857421875, val_loss: 92.9943618774414\n",
      "41, train_loss: -333.0231018066406, val_loss: 87.21951293945312\n",
      "42, train_loss: -319.2498779296875, val_loss: 83.59516906738281\n",
      "43, train_loss: -322.8204650878906, val_loss: 79.47588348388672\n",
      "44, train_loss: -337.6685485839844, val_loss: 74.94248962402344\n",
      "45, train_loss: -351.7135925292969, val_loss: 73.51824188232422\n",
      "46, train_loss: -346.7464294433594, val_loss: 70.46768188476562\n",
      "47, train_loss: -364.9796142578125, val_loss: 63.70906448364258\n",
      "48, train_loss: -351.9943542480469, val_loss: 62.58614730834961\n",
      "49, train_loss: -353.8883361816406, val_loss: 58.92765426635742\n",
      "50, train_loss: -361.6423034667969, val_loss: 55.65040588378906\n",
      "51, train_loss: -397.13916015625, val_loss: 52.2357292175293\n",
      "52, train_loss: -394.2862854003906, val_loss: 48.607322692871094\n",
      "53, train_loss: -396.88336181640625, val_loss: 45.52362823486328\n",
      "54, train_loss: -399.4114990234375, val_loss: 47.49877166748047\n",
      "55, train_loss: -388.28680419921875, val_loss: 42.622589111328125\n",
      "56, train_loss: -402.50262451171875, val_loss: 38.30940628051758\n",
      "57, train_loss: -390.94537353515625, val_loss: 34.84811782836914\n",
      "58, train_loss: -424.5412292480469, val_loss: 32.942596435546875\n",
      "59, train_loss: -427.0008544921875, val_loss: 31.787200927734375\n",
      "60, train_loss: -426.5089111328125, val_loss: 28.634944915771484\n",
      "61, train_loss: -421.1832580566406, val_loss: 24.54212760925293\n",
      "62, train_loss: -442.4342346191406, val_loss: 20.080108642578125\n",
      "63, train_loss: -467.51513671875, val_loss: 19.946020126342773\n",
      "64, train_loss: -457.6025695800781, val_loss: 22.06496238708496\n",
      "65, train_loss: -465.43719482421875, val_loss: 19.65499496459961\n",
      "66, train_loss: -439.8511047363281, val_loss: 15.151311874389648\n",
      "67, train_loss: -481.5456848144531, val_loss: 14.453080177307129\n",
      "68, train_loss: -475.8747863769531, val_loss: 11.584284782409668\n",
      "69, train_loss: -459.5985107421875, val_loss: 8.024667739868164\n",
      "70, train_loss: -489.14251708984375, val_loss: 4.694930076599121\n",
      "71, train_loss: -452.98876953125, val_loss: 3.5681066513061523\n",
      "72, train_loss: -488.6728820800781, val_loss: 0.9653711318969727\n",
      "73, train_loss: -510.8085021972656, val_loss: -1.1659860610961914\n",
      "74, train_loss: -494.96575927734375, val_loss: 0.19054794311523438\n",
      "75, train_loss: -504.3810729980469, val_loss: -6.461136817932129\n",
      "76, train_loss: -502.4349060058594, val_loss: -12.04116153717041\n",
      "77, train_loss: -509.9095458984375, val_loss: -8.094856262207031\n",
      "78, train_loss: -482.33477783203125, val_loss: -3.8152284622192383\n",
      "79, train_loss: -516.4653930664062, val_loss: 0.6718683242797852\n",
      "80, train_loss: -514.2198486328125, val_loss: -6.75324821472168\n",
      "81, train_loss: -507.04498291015625, val_loss: -9.003711700439453\n",
      "82, train_loss: -511.8407897949219, val_loss: -12.852090835571289\n",
      "83, train_loss: -514.8373413085938, val_loss: -17.072216033935547\n",
      "84, train_loss: -545.2196655273438, val_loss: -19.672731399536133\n",
      "85, train_loss: -541.7974243164062, val_loss: -18.261390686035156\n",
      "86, train_loss: -547.5769653320312, val_loss: -17.16165542602539\n",
      "87, train_loss: -543.7289428710938, val_loss: -21.044837951660156\n",
      "88, train_loss: -560.5133666992188, val_loss: -25.455591201782227\n",
      "89, train_loss: -570.6869506835938, val_loss: -26.173744201660156\n",
      "90, train_loss: -549.1693115234375, val_loss: -28.819461822509766\n",
      "91, train_loss: -566.6898803710938, val_loss: -32.318416595458984\n",
      "92, train_loss: -543.1115112304688, val_loss: -34.66828536987305\n",
      "93, train_loss: -559.2506103515625, val_loss: -38.460731506347656\n",
      "94, train_loss: -557.8690185546875, val_loss: -47.17937088012695\n",
      "95, train_loss: -555.5809326171875, val_loss: -50.17201232910156\n",
      "96, train_loss: -572.3615112304688, val_loss: -51.97796630859375\n",
      "97, train_loss: -603.731689453125, val_loss: -49.860145568847656\n",
      "98, train_loss: -597.0166015625, val_loss: -48.72185516357422\n",
      "99, train_loss: -589.84521484375, val_loss: -49.14801025390625\n",
      "100, train_loss: -596.3123779296875, val_loss: -47.0843505859375\n",
      "101, train_loss: -620.54833984375, val_loss: -47.65932846069336\n",
      "102, train_loss: -595.9002075195312, val_loss: -51.23563003540039\n",
      "103, train_loss: -604.2749633789062, val_loss: -47.74458694458008\n",
      "104, train_loss: -607.650390625, val_loss: -47.603973388671875\n",
      "105, train_loss: -613.7071533203125, val_loss: -44.91853332519531\n",
      "106, train_loss: -631.0112915039062, val_loss: -50.85013961791992\n",
      "107, train_loss: -635.9075927734375, val_loss: -53.57886505126953\n",
      "108, train_loss: -642.3162231445312, val_loss: -59.51319122314453\n",
      "109, train_loss: -619.5574951171875, val_loss: -64.33430480957031\n",
      "110, train_loss: -623.8176879882812, val_loss: -66.7156753540039\n",
      "111, train_loss: -617.7227783203125, val_loss: -72.10464477539062\n",
      "112, train_loss: -636.9995727539062, val_loss: -68.64788055419922\n",
      "113, train_loss: -642.8910522460938, val_loss: -65.50438690185547\n",
      "114, train_loss: -636.4735107421875, val_loss: -69.55789184570312\n",
      "115, train_loss: -646.5911254882812, val_loss: -67.4098129272461\n",
      "116, train_loss: -639.410400390625, val_loss: -68.87574005126953\n",
      "117, train_loss: -648.6370239257812, val_loss: -69.37409973144531\n",
      "118, train_loss: -666.6680908203125, val_loss: -76.04920959472656\n",
      "119, train_loss: -658.0435180664062, val_loss: -78.14059448242188\n",
      "120, train_loss: -673.0201416015625, val_loss: -76.74154663085938\n",
      "121, train_loss: -670.2763061523438, val_loss: -73.95832824707031\n",
      "122, train_loss: -674.0878295898438, val_loss: -76.62911987304688\n",
      "123, train_loss: -668.267333984375, val_loss: -76.43171691894531\n",
      "124, train_loss: -687.37890625, val_loss: -78.81240844726562\n",
      "125, train_loss: -676.5140380859375, val_loss: -80.14543151855469\n",
      "126, train_loss: -690.2431640625, val_loss: -81.2076416015625\n",
      "127, train_loss: -686.298828125, val_loss: -82.36273193359375\n",
      "128, train_loss: -696.5942993164062, val_loss: -88.15577697753906\n",
      "129, train_loss: -695.8496704101562, val_loss: -87.47654724121094\n",
      "130, train_loss: -703.3076171875, val_loss: -85.11932373046875\n",
      "131, train_loss: -676.3219604492188, val_loss: -87.57139587402344\n",
      "132, train_loss: -695.8886108398438, val_loss: -92.06838989257812\n",
      "133, train_loss: -710.703125, val_loss: -95.07695770263672\n",
      "134, train_loss: -713.7227783203125, val_loss: -97.47113800048828\n",
      "135, train_loss: -710.519287109375, val_loss: -97.9893569946289\n",
      "136, train_loss: -718.5031127929688, val_loss: -98.30686950683594\n",
      "137, train_loss: -714.5611572265625, val_loss: -99.8955078125\n",
      "138, train_loss: -710.7755126953125, val_loss: -96.22425842285156\n",
      "139, train_loss: -715.8932495117188, val_loss: -97.14865112304688\n",
      "140, train_loss: -722.8118896484375, val_loss: -103.90035247802734\n",
      "141, train_loss: -742.8668212890625, val_loss: -102.66068267822266\n",
      "142, train_loss: -720.4126586914062, val_loss: -102.14064025878906\n",
      "143, train_loss: -722.4844360351562, val_loss: -106.70672607421875\n",
      "144, train_loss: -748.4329833984375, val_loss: -109.11090087890625\n",
      "145, train_loss: -743.4629516601562, val_loss: -110.30728149414062\n",
      "146, train_loss: -749.8622436523438, val_loss: -109.91012573242188\n",
      "147, train_loss: -734.4091186523438, val_loss: -110.23878479003906\n",
      "148, train_loss: -753.6607666015625, val_loss: -117.56356811523438\n",
      "149, train_loss: -752.3215942382812, val_loss: -114.72036743164062\n",
      "150, train_loss: -765.9506225585938, val_loss: -115.33428192138672\n",
      "151, train_loss: -751.1548461914062, val_loss: -113.49024963378906\n",
      "152, train_loss: -758.8834228515625, val_loss: -116.98439025878906\n",
      "153, train_loss: -762.3051147460938, val_loss: -121.1258544921875\n",
      "154, train_loss: -742.3246459960938, val_loss: -118.59196472167969\n",
      "155, train_loss: -772.4362182617188, val_loss: -117.18186950683594\n",
      "156, train_loss: -773.4246215820312, val_loss: -118.18550109863281\n",
      "157, train_loss: -770.6387939453125, val_loss: -120.60049438476562\n",
      "158, train_loss: -781.3359375, val_loss: -126.08434295654297\n",
      "159, train_loss: -786.5769653320312, val_loss: -123.88313293457031\n",
      "160, train_loss: -752.9794921875, val_loss: -124.08761596679688\n",
      "161, train_loss: -758.4093017578125, val_loss: -123.30511474609375\n",
      "162, train_loss: -781.3457641601562, val_loss: -126.82676696777344\n",
      "163, train_loss: -787.5386352539062, val_loss: -133.31185913085938\n",
      "164, train_loss: -797.5866088867188, val_loss: -132.41297912597656\n",
      "165, train_loss: -788.1566772460938, val_loss: -132.45608520507812\n",
      "166, train_loss: -809.3140258789062, val_loss: -129.66806030273438\n",
      "167, train_loss: -793.5767822265625, val_loss: -123.03921508789062\n",
      "168, train_loss: -785.7235717773438, val_loss: -121.52545166015625\n",
      "169, train_loss: -791.6295166015625, val_loss: -123.4825210571289\n",
      "170, train_loss: -776.7630615234375, val_loss: -120.41921997070312\n",
      "171, train_loss: -794.2476196289062, val_loss: -122.3913345336914\n",
      "172, train_loss: -805.087646484375, val_loss: -121.8820571899414\n",
      "173, train_loss: -816.6625366210938, val_loss: -125.55941772460938\n",
      "174, train_loss: -815.8707885742188, val_loss: -130.3031463623047\n",
      "175, train_loss: -811.1746826171875, val_loss: -132.55084228515625\n",
      "176, train_loss: -826.2527465820312, val_loss: -131.91741943359375\n",
      "177, train_loss: -828.9409790039062, val_loss: -126.58606719970703\n",
      "178, train_loss: -833.5618896484375, val_loss: -126.94450378417969\n",
      "179, train_loss: -810.5067138671875, val_loss: -125.78043365478516\n",
      "180, train_loss: -808.071533203125, val_loss: -129.3197021484375\n",
      "181, train_loss: -824.0341796875, val_loss: -133.44300842285156\n",
      "182, train_loss: -826.13671875, val_loss: -131.71275329589844\n",
      "183, train_loss: -831.7307739257812, val_loss: -131.4570770263672\n",
      "184, train_loss: -846.4505004882812, val_loss: -134.8530731201172\n",
      "185, train_loss: -842.41748046875, val_loss: -135.80970764160156\n",
      "186, train_loss: -851.89453125, val_loss: -136.45912170410156\n",
      "187, train_loss: -851.7989501953125, val_loss: -136.30392456054688\n",
      "188, train_loss: -875.3082885742188, val_loss: -137.06890869140625\n",
      "189, train_loss: -865.4884033203125, val_loss: -142.5540771484375\n",
      "190, train_loss: -861.8273315429688, val_loss: -143.95361328125\n",
      "191, train_loss: -867.5398559570312, val_loss: -141.22607421875\n",
      "192, train_loss: -868.298095703125, val_loss: -143.69989013671875\n",
      "193, train_loss: -867.1812744140625, val_loss: -142.24801635742188\n",
      "194, train_loss: -877.57421875, val_loss: -141.6649169921875\n",
      "195, train_loss: -886.5916748046875, val_loss: -141.9923553466797\n",
      "196, train_loss: -856.0416870117188, val_loss: -143.49020385742188\n",
      "197, train_loss: -859.6546630859375, val_loss: -139.68499755859375\n",
      "198, train_loss: -836.1282958984375, val_loss: -135.23243713378906\n",
      "199, train_loss: -875.0489501953125, val_loss: -142.51406860351562\n",
      "Test loss: -187.6757354736328 at epoch: 199\n",
      "Average test log likelihood: 187.6757354736328 at epoch: 199\n",
      "Min val loss: -143.95361328125 at epoch: 190\n",
      "Last val loss: -142.51406860351562 at epoch: 199\n",
      "Min train loss: -886.5916748046875 at epoch: 195\n",
      "Last train loss: -875.0489501953125 at epoch: 199\n",
      "Training time: 324.99434089660645\n",
      "Test time: 0.5279128551483154\n"
     ]
    }
   ],
   "source": [
    "global_step = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "min_val_loss = tf.convert_to_tensor(np.inf, dtype=tf.float32)  # high value to ensure that first loss < min_loss\n",
    "min_train_loss = tf.convert_to_tensor(np.inf, dtype=tf.float32)\n",
    "min_val_epoch = 0\n",
    "min_train_epoch = 0\n",
    "delta_stop = 50  # threshold for early stopping\n",
    "\n",
    "t_start = time.time()  # start time\n",
    "\n",
    "# start training\n",
    "for i in range(max_epochs):\n",
    "\n",
    "    train_data.shuffle(buffer_size=1000)\n",
    "    batch_train_losses = []\n",
    "    for batch in train_data:\n",
    "        batch_loss = train_density_estimation(flow, opt, batch)\n",
    "        batch_train_losses.append(batch_loss)\n",
    "\n",
    "    train_loss = tf.reduce_mean(batch_train_losses)\n",
    "\n",
    "    if i % int(1) == 0:\n",
    "        batch_val_losses = []\n",
    "        for batch in val_data:\n",
    "            batch_loss = nll(flow, batch)\n",
    "            batch_val_losses.append(batch_loss)\n",
    "\n",
    "        val_loss = tf.reduce_mean(batch_val_losses)\n",
    "\n",
    "        global_step.append(i)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"{i}, train_loss: {train_loss}, val_loss: {val_loss}\")\n",
    "\n",
    "        if train_loss < min_train_loss:\n",
    "            min_train_loss = train_loss\n",
    "            min_train_epoch = i\n",
    "\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            min_val_epoch = i\n",
    "            checkpoint.write(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        elif i - min_val_epoch > delta_stop:  # no decrease in min_val_loss for \"delta_stop epochs\"\n",
    "            break\n",
    "\n",
    "train_time = time.time() - t_start\n",
    "\n",
    "# load best model with min validation loss\n",
    "checkpoint.restore(checkpoint_prefix)\n",
    "\n",
    "# perform on test dataset\n",
    "t_start = time.time()\n",
    "\n",
    "test_losses = []\n",
    "for batch in test_data:\n",
    "    batch_loss = nll(flow, batch)\n",
    "    test_losses.append(batch_loss)\n",
    "\n",
    "test_loss = tf.reduce_mean(test_losses)\n",
    "\n",
    "test_time = time.time() - t_start\n",
    "\n",
    "save_dir = \"{}/sampling_{}_{}_{}_{}/\".format(dataset, layers, shape[0], shape[1], category)\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "for j in range(n_images):\n",
    "    plt.figure()\n",
    "    data = flow.sample(1)\n",
    "    data = dataset_loader.inverse_logit(data)\n",
    "    data = tf.reshape(data, (1, size, size))\n",
    "    plt.imshow(data[0], cmap='gray')\n",
    "    plt.savefig(\"{}/{}_{}_i{}.png\".format(save_dir, exp_number, min_val_epoch, j))\n",
    "    plt.close()\n",
    "\n",
    "# remove checkpoint\n",
    "filelist = [f for f in os.listdir(checkpoint_directory)]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(checkpoint_directory, f))\n",
    "os.removedirs(checkpoint_directory)\n",
    "\n",
    "print(f'Test loss: {test_loss} at epoch: {i}')\n",
    "print(f'Average test log likelihood: {-test_loss} at epoch: {i}')\n",
    "print(f'Min val loss: {min_val_loss} at epoch: {min_val_epoch}')\n",
    "print(f'Last val loss: {val_loss} at epoch: {i}')\n",
    "print(f'Min train loss: {min_train_loss} at epoch: {min_train_epoch}')\n",
    "print(f'Last train loss: {train_loss} at epoch: {i}')\n",
    "print(f'Training time: {train_time}')\n",
    "print(f'Test time: {test_time}')\n",
    "\n",
    "results = {\n",
    "    'test_loss': float(test_loss),\n",
    "    'avg_test_logll': float(-test_loss),\n",
    "    'min_val_loss': float(min_val_loss),\n",
    "    'min_val_epoch': min_val_epoch,\n",
    "    'val_loss': float(val_loss),\n",
    "    'min_train_loss': float(min_train_loss),\n",
    "    'min_train_epoch': min_train_epoch,\n",
    "    'train_loss': float(train_loss),\n",
    "    'train_time': train_time,\n",
    "    'test_time': test_time,\n",
    "    'trained_epochs': i,\n",
    "    'trainable variables': n_trainable_variables,\n",
    "    'exp_number': exp_number\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
